{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T04:17:31.203280Z",
     "start_time": "2024-05-31T04:17:00.327391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "import itertools\n",
    "np.seterr(divide='ignore')\n",
    "\n",
    "\n",
    "def assert_dist_non_negative(log_p):\n",
    "    assert np.all(log_p <= 0)\n",
    "\n",
    "\n",
    "def assert_dist_sums_to_1(log_p, axis, check_idx=None):\n",
    "    if check_idx is None: assert np.all(np.isclose(np.exp(logsumexp(log_p, axis=axis)), 1))\n",
    "    else: assert np.all(np.isclose(np.exp(logsumexp(log_p, axis=axis)[check_idx]), 1))\n",
    "\n",
    "\n",
    "def _log_forward(data_obs, log_p, log_t_mat, log_e_mat, val_X, T):\n",
    "    \"\"\"\n",
    "    F[1, k] = p(X_1 = k, o_1) = p(o_1 | X_1 = k) * p(X_1 = k) = e[k -> o_1] * p[k]\n",
    "    F[t, k] = p(X_t = k, o_{1:t}) = e[k -> o_t] * sum_l[ F[t-1, l] * tau[l -> k] ]\n",
    "    shape = N x T x |Val(X)|\n",
    "    \"\"\"\n",
    "    N = data_obs.shape[0]\n",
    "    log_F = np.zeros((N, T, len(val_X))) - np.inf\n",
    "    log_F[:, 0] = log_p + log_e_mat[:, data_obs[:, 0]].T\n",
    "    for t in range(1, T):\n",
    "        temp = log_F[:, t - 1, None] + log_t_mat.T[None, :]\n",
    "        log_F[:, t] = logsumexp(temp + log_e_mat[:, data_obs[:, t]].T[:, :, None], axis=2)\n",
    "\n",
    "    # tests\n",
    "    assert_dist_non_negative(log_F)\n",
    "    return log_F\n",
    "\n",
    "\n",
    "class HMM:\n",
    "    def __init__(self, T, val_X, val_O, prior, transition_mat, emission_mat):\n",
    "        self.T = T\n",
    "        self.val_X = val_X\n",
    "        self.val_O = val_O\n",
    "        self.log_prior = np.log(prior)\n",
    "        self.log_transition_mat = np.log(transition_mat)\n",
    "        self.log_emission_mat = np.log(emission_mat)\n",
    "\n",
    "    def get_CPDs(self):\n",
    "        return {'prior': np.exp(self.log_prior),\n",
    "                'transition_mat': np.exp(self.log_transition_mat),\n",
    "                'emission_mat': np.exp(self.log_emission_mat)}\n",
    "\n",
    "    def print_CPDs(self):\n",
    "        cpds = self.get_CPDs()\n",
    "        k = 'prior'\n",
    "        print(k)\n",
    "        print(np.array([f'prior({x})={cpds[k][x]:.3f}' for x in self.val_X]))\n",
    "        k = 'transition_mat'\n",
    "        print(k)\n",
    "        print(np.array([[f'tau({xt}->{xtp1})={cpds[k][xtp1][xt]:.3f}' for xt in self.val_X] for xtp1 in self.val_X]))\n",
    "        k = 'emission_mat'\n",
    "        print(k)\n",
    "        print(np.array([[f'e({xt}->{ot})={cpds[k][xt][ot]:.3f}' for ot in self.val_O] for xt in self.val_X]))\n",
    "\n",
    "    ########################################\n",
    "    ##########      Sampling      ##########\n",
    "    ########################################\n",
    "    def sample(self, N=1):\n",
    "        \"\"\"\n",
    "        TODO sample N samples from the HMM.\n",
    "        Assumes that the HMM CPDs are defined.\n",
    "        :param N: optional, default=1. Number of samples.\n",
    "        :return: (hidden, obs) for N samples from the HMM. shape of hidden & obs = (N,hmm.T)\n",
    "        \"\"\"\n",
    "        cpds = self.get_CPDs()\n",
    "\n",
    "        hidden_samples = np.zeros((N, self.T), dtype=int)\n",
    "        obs_samples = np.zeros((N, self.T), dtype=int)\n",
    "        \n",
    "        for n in range(N): \n",
    "            hidden_samples[n, 0] = np.random.choice(self.val_X, p=cpds['prior'])\n",
    "            obs_samples[n, 0] = np.random.choice(self.val_O, p=cpds['emission_mat'][hidden_samples[n, 0]])\n",
    "\n",
    "            for t in range(1, self.T):\n",
    "                hidden_samples[n, t] = np.random.choice(self.val_X, p=cpds['transition_mat'][hidden_samples[n, t-1]])\n",
    "                obs_samples[n, t] = np.random.choice(self.val_O, p=cpds['emission_mat'][hidden_samples[n, t]])\n",
    "\n",
    "        return (hidden_samples, obs_samples)\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "    ########################################\n",
    "    ##########     Calc Prob.     ##########\n",
    "    ########################################\n",
    "    def log_joint(self, hidden, obs):\n",
    "        \"\"\"\n",
    "        TODO calculate the log joint probability of the hidden, observations sequences for each sample p(x1:T[t],o1:T[i]).\n",
    "        :param hidden - N hidden sequences. shape = (N,T)\n",
    "        :param obs - N observations. shape = (N,T)\n",
    "        :return log-joint probability. shape = (N)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def naive_log_likelihood(self, obs):\n",
    "        \"\"\"\n",
    "        Calculate the log likelihood of the observations for each sample p(o1:T[i]) in a naive way (going over all\n",
    "        possibilities). This will take many resources for T>5.\n",
    "        :param obs - N observations. shape = (N,T)\n",
    "        :return log-likelihood. shape = (N)\n",
    "        \"\"\"\n",
    "        assert self.T < 6\n",
    "        X = set(itertools.permutations(np.array([[x] * self.T for x in self.val_X]).flatten(), self.T))\n",
    "        p = []\n",
    "        for x in X:\n",
    "            p.append(self.log_joint(np.broadcast_to(x, obs.shape), obs))\n",
    "        return logsumexp(p, axis=0)\n",
    "\n",
    "    def log_likelihood(self, obs):\n",
    "        \"\"\"\n",
    "        TODO calculate the log likelihood of the observations for each sample p(o1:T[i]).\n",
    "             Use the supplied forward-algorithm.\n",
    "        :param obs - N observations. shape = (N,T)\n",
    "        :return log-likelihood. shape = (N)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def log_prior_Xt(self):\n",
    "        \"\"\"\n",
    "        TODO calculate the point-wise prior p(X_t=x)\n",
    "        :return point-wise prior. shape = (T, |val(X)|)\n",
    "        \"\"\"\n",
    "        log_p_Xt = None\n",
    "        # tests\n",
    "        assert_dist_non_negative(log_p_Xt)   # p(Xt = k) >= 0\n",
    "        assert_dist_sums_to_1(log_p_Xt, axis=-1)  # sum_k[ p(Xt = k) ] == 1\n",
    "        return log_p_Xt\n",
    "\n",
    "    def log_naive_posterior_Xt(self, obs):\n",
    "        \"\"\"\n",
    "        TODO calculate the point-wise posterior p(X_t=x | ot=obs[i][t])\n",
    "        :param obs - N observations. shape = (N,T)\n",
    "        :return point-wise posterior. shape = (N, T, |val(X)|)\n",
    "        \"\"\"\n",
    "        log_posterior_Xt_given_Ot = None\n",
    "        # tests\n",
    "        assert_dist_non_negative(log_posterior_Xt_given_Ot)  # p(Xt = k | ot) >= 0\n",
    "        assert_dist_sums_to_1(log_posterior_Xt_given_Ot, axis=-1)  # sum_k[ p(Xt = k | ot) ] == 1\n",
    "        return log_posterior_Xt_given_Ot\n",
    "\n",
    "    ########################################\n",
    "    ##########     Prediction     ##########\n",
    "    ########################################\n",
    "    def naive_predict_by_naive_posterior(self, obs):\n",
    "        \"\"\"\n",
    "        TODO predict a sequence of hidden states for each sample using the point-wise posterior:\n",
    "            X_hat[i][t] = argmax_x[ p(X_t=x | ot=obs[i][t]) ]\n",
    "        :param obs - N observations. shape = (N,T)\n",
    "        :return X_hat - N hidden sequences. shape = (N,T)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "########################################\n",
    "########################################\n",
    "########################################\n",
    "########################################\n",
    "########################################\n",
    "########################################\n",
    "########################################\n",
    "########################################\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "# from HMM_proj1 import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "########################################\n",
    "##########        Utils       ##########\n",
    "########################################\n",
    "def load_data(file_name, data_path='data/'):\n",
    "    return pd.read_csv(data_path + file_name + '.csv', index_col=0).values\n",
    "\n",
    "\n",
    "def get_hmm(num_hmm):\n",
    "    # define HMMs\n",
    "    val_X = np.arange(2)\n",
    "    val_O = np.arange(2)\n",
    "    if num_hmm == 1:\n",
    "        hmm_params = {\n",
    "            'prior': np.array([0.849, 0.151]),\n",
    "            'transition_mat': np.array([[0.75, 0.25],  # p(X_{t+1}=x | X_t=0)\n",
    "                                        [0.25, 0.75]]),   # p(X_{t+1}=x | X_t=1)\n",
    "            'emission_mat': np.array([[0.83, 0.17], # p(O_t=o | X_t = 0)\n",
    "                                      [0.17, 0.83]]) # p(O_t=o | X_t = 1)\n",
    "        }\n",
    "        T = 1000\n",
    "\n",
    "    elif num_hmm == 2:\n",
    "        hmm_params = {\n",
    "            'prior': np.array([1, 0]),\n",
    "            'transition_mat': np.array([[0.999, 0.001],\n",
    "                                        [0.005, 0.995]]),\n",
    "            'emission_mat': np.array([[0.99, 0.01],\n",
    "                                      [0.01, 0.99]])\n",
    "        }\n",
    "        T = 1000\n",
    "    elif num_hmm == 3:\n",
    "        hmm_params = {\n",
    "            'prior': np.array([1, 0]),\n",
    "            'transition_mat': np.array([[0.999, 0.001],\n",
    "                                        [0, 1]]),\n",
    "            'emission_mat': np.array([[0.99, 0.01],\n",
    "                                      [0.01, 0.99]])\n",
    "        }\n",
    "        T = 1000\n",
    "\n",
    "    hmm = HMM(T=T, val_X=val_X, val_O=val_O, prior=hmm_params['prior'],\n",
    "               transition_mat=hmm_params['transition_mat'], emission_mat=hmm_params['emission_mat'])\n",
    "    print(f'Load HMM{num_hmm}. CPDs:')\n",
    "    hmm.print_CPDs()\n",
    "    print()\n",
    "    print()\n",
    "    return hmm\n",
    "\n",
    "\n",
    "########################################\n",
    "##########         Q2         ##########\n",
    "########################################\n",
    "def plot_sequence(sequences, seq_name=None, fig_name='', figsize=(20, 3)):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    ax.plot(sequences)\n",
    "    ax.set_title(f'Sequence of {seq_name} variables, {sequences.shape[1]} samples')\n",
    "    ax.set_xlabel('T')\n",
    "    ax.set_ylabel('modification status')\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f'plots/{fig_name}_sequence_{seq_name.lower()}', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_heatmap(table, table_name=None, fig_name='', figsize=(8, 4)):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    sns.heatmap(table, cmap='YlOrRd', ax=ax)\n",
    "    ax.set_title(f'{table_name} variables, {table.shape[0]} samples')\n",
    "    ax.set_xlabel('T')\n",
    "    ax.set_ylabel('samples')\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f'plots/{fig_name}_heatmap_{table_name.lower()}', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_histogram(scores, score_names=None, fig_name='', bins=20):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "    ax.hist(scores, bins=bins, density=True)\n",
    "    ax.set_title(f'{score_names} histogram')\n",
    "    ax.set_xlabel('log-joint probability')\n",
    "    ax.set_ylabel('density')\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f'plots/{fig_name}_hist_{score_names.lower()}', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_samples(obs, hidden=None, N_plot=3, fig_name='hmm'):\n",
    "    if hidden is not None: plot_sequence(hidden[:N_plot].T, seq_name=f'hidden', fig_name=fig_name)\n",
    "    plot_sequence(obs[:N_plot].T, seq_name=f'observed', fig_name=fig_name)\n",
    "    plot_heatmap(obs, table_name='Observed', fig_name=fig_name)\n",
    "\n",
    "\n",
    "def Q2_sampling(hmm, fig_name='hmm', N=100):\n",
    "    \"\"\"\n",
    "    Samples N samples from the HMM. Calculates the log joint probability of each sample.\n",
    "    Plots:\n",
    "        1. The hidden sequence of 3 samples.\n",
    "        2. The observed sequence of 3 samples.\n",
    "        3. A heatmap for all the observed samples.\n",
    "        4. A histogram of the log joint probabilities.\n",
    "    \"\"\"\n",
    "    hidden, obs = hmm.sample(N)\n",
    "    log_joint = hmm.log_joint(hidden, obs)\n",
    "    plot_samples(obs, hidden, fig_name=fig_name)\n",
    "    plot_histogram(log_joint, score_names='Log-joint', bins=20, fig_name=fig_name)\n",
    "\n",
    "\n",
    "########################################\n",
    "##########         Q4         ##########\n",
    "########################################\n",
    "def Q4_identify_corrupt_data(hmm):\n",
    "    \"\"\"\n",
    "    Loads the data and plots the histograms. Rest is TODO.\n",
    "    Your job is to compute the validation_marginal_log_likelihood, real_marginal_log_likelihood and\n",
    "    corrupt_marginal_log_likelihood below.\n",
    "    \"\"\"\n",
    "    # get data\n",
    "    validation_data = load_data('validation_data')\n",
    "    test_data = load_data('test_data')\n",
    "    '''\n",
    "    TODO. Calculate marginal_log_likelihood on validation data, define prediction rule, \n",
    "            and calculate marginal_log_likelihood of test samples classified as real and as corrupted.\n",
    "    '''\n",
    "    validation_marginal_log_likelihood = None\n",
    "    real_marginal_log_likelihood = None\n",
    "    corrupt_marginal_log_likelihood = None\n",
    "\n",
    "    # plot histograms\n",
    "    plt.title('Histogram of marginal log-likelihood')\n",
    "    mi = np.min([corrupt_marginal_log_likelihood.min(), real_marginal_log_likelihood.min(),\n",
    "                 validation_marginal_log_likelihood.min()])\n",
    "    _, bins, _ = plt.hist(validation_marginal_log_likelihood, label='validation data', bins=np.arange(mi - 10, 0, 4))\n",
    "    plt.hist(real_marginal_log_likelihood, label='real test data', bins=bins)\n",
    "    plt.hist(corrupt_marginal_log_likelihood, label='corrupted test data', bins=bins)\n",
    "    plt.xlabel('marginal log-likelihood')\n",
    "    plt.ylabel('frequency')\n",
    "    plt.legend()\n",
    "    plt.savefig('plots/Q4_hist', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "########################################\n",
    "##########         Q5         ##########\n",
    "########################################\n",
    "def accuracy(true, pred):\n",
    "    return np.mean(true == pred)\n",
    "\n",
    "\n",
    "def test_pred(hmm, data_obs, data_hidden, val_X, invalid_transitions=None):\n",
    "    def check_invalid_transitions(X_hat):\n",
    "        if invalid_transitions is not None:\n",
    "            for (xt, xtp1) in invalid_transitions:\n",
    "                print(f'# invalid transitions from {xt} to {xtp1}')\n",
    "                print(np.sum([((X_hat[:, t] == 1) & (X_hat[:, t + 1] == 0)).sum() for t in range(hmm.T - 1)]))\n",
    "\n",
    "    X_hat = hmm.naive_predict_by_naive_posterior(data_obs)\n",
    "    print(f'Naive prediction accuracy = {accuracy(data_hidden.flatten(), X_hat.flatten())}, confusion mat:')\n",
    "    print(confusion_matrix(data_hidden.flatten(), X_hat.flatten(), labels=val_X))\n",
    "    check_invalid_transitions(X_hat)\n",
    "\n",
    "\n",
    "def Q5_naive_predication(hmm, N=100):\n",
    "    hidden, obs = hmm.sample(N)\n",
    "    test_pred(hmm, obs, hidden, hmm.val_X, invalid_transitions=[(1, 0)])\n",
    "\n",
    "# \n",
    "# if __name__ == '__main__':\n",
    "#     if not os.path.exists('plots/'): os.mkdir('plots/')\n",
    "# \n",
    "#     # Q2\n",
    "#     print('''\n",
    "#         ########################################\n",
    "#         ##########         Q2         ##########\n",
    "#         ########################################\n",
    "#     ''')\n",
    "#     hmm1 = get_hmm(1)\n",
    "#     Q2_sampling(hmm1, fig_name='Q2_hmm1')\n",
    "#     hmm2 = get_hmm(2)\n",
    "#     Q2_sampling(hmm2, fig_name='Q2_hmm2')\n",
    "#     small_data = load_data('small_binary_data')\n",
    "#     plot_samples(small_data, fig_name='Q2_real_data')\n",
    "# \n",
    "#     # Q4\n",
    "#     print('''\n",
    "#         ########################################\n",
    "#         ##########         Q4         ##########\n",
    "#         ########################################\n",
    "#     ''')\n",
    "#     hmm2 = get_hmm(2)\n",
    "#     Q4_identify_corrupt_data(hmm2)\n",
    "# \n",
    "#     # Q5\n",
    "#     print('''\n",
    "#         ########################################\n",
    "#         ##########         Q5         ##########\n",
    "#         ########################################\n",
    "#     ''')\n",
    "#     hmm3 = get_hmm(3)\n",
    "#     Q5_naive_predication(hmm3)\n",
    "\n",
    "\n",
    "# Q2\n",
    "print('''\n",
    "    ########################################\n",
    "    ##########         Q2         ##########\n",
    "    ########################################\n",
    "''')\n",
    "hmm1 = get_hmm(1)\n",
    "Q2_sampling(hmm1, fig_name='Q2_hmm1')\n",
    "\n",
    "\n",
    "# hmm2 = get_hmm(2)\n",
    "# Q2_sampling(hmm2, fig_name='Q2_hmm2')\n",
    "# small_data = load_data('small_binary_data')\n",
    "# plot_samples(small_data, fig_name='Q2_real_data')\n"
   ],
   "id": "62ba36b06888a3f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ########################################\n",
      "    ##########         Q2         ##########\n",
      "    ########################################\n",
      "\n",
      "Load HMM1. CPDs:\n",
      "prior\n",
      "['prior(0)=0.849' 'prior(1)=0.151']\n",
      "transition_mat\n",
      "[['tau(0->0)=0.750' 'tau(1->0)=0.250']\n",
      " ['tau(0->1)=0.250' 'tau(1->1)=0.750']]\n",
      "emission_mat\n",
      "[['e(0->0)=0.830' 'e(0->1)=0.170']\n",
      " ['e(1->0)=0.170' 'e(1->1)=0.830']]\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 385\u001B[0m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'''\u001B[39m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;124m    ########################################\u001B[39m\n\u001B[1;32m    381\u001B[0m \u001B[38;5;124m    ##########         Q2         ##########\u001B[39m\n\u001B[1;32m    382\u001B[0m \u001B[38;5;124m    ########################################\u001B[39m\n\u001B[1;32m    383\u001B[0m \u001B[38;5;124m'''\u001B[39m)\n\u001B[1;32m    384\u001B[0m hmm1 \u001B[38;5;241m=\u001B[39m get_hmm(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m--> 385\u001B[0m \u001B[43mQ2_sampling\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhmm1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfig_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mQ2_hmm1\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    388\u001B[0m \u001B[38;5;66;03m# hmm2 = get_hmm(2)\u001B[39;00m\n\u001B[1;32m    389\u001B[0m \u001B[38;5;66;03m# Q2_sampling(hmm2, fig_name='Q2_hmm2')\u001B[39;00m\n\u001B[1;32m    390\u001B[0m \u001B[38;5;66;03m# small_data = load_data('small_binary_data')\u001B[39;00m\n\u001B[1;32m    391\u001B[0m \u001B[38;5;66;03m# plot_samples(small_data, fig_name='Q2_real_data')\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[30], line 280\u001B[0m, in \u001B[0;36mQ2_sampling\u001B[0;34m(hmm, fig_name, N)\u001B[0m\n\u001B[1;32m    278\u001B[0m hidden, obs \u001B[38;5;241m=\u001B[39m hmm\u001B[38;5;241m.\u001B[39msample(N)\n\u001B[1;32m    279\u001B[0m log_joint \u001B[38;5;241m=\u001B[39m hmm\u001B[38;5;241m.\u001B[39mlog_joint(hidden, obs)\n\u001B[0;32m--> 280\u001B[0m \u001B[43mplot_samples\u001B[49m(obs, hidden, fig_name\u001B[38;5;241m=\u001B[39mfig_name)\n\u001B[1;32m    281\u001B[0m plot_histogram(log_joint, score_names\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLog-joint\u001B[39m\u001B[38;5;124m'\u001B[39m, bins\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m, fig_name\u001B[38;5;241m=\u001B[39mfig_name)\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_312_64.pyx:1187\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_312_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_312_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_312_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_312_64.pyx:937\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_312_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_312_64.pyx:928\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_312_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_312_64.pyx:585\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_312_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1185\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1182\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1184\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1185\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1200\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1197\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1199\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1200\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1202\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1204\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6d89f52f3c55106f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
